# -*- coding: utf-8 -*-
"""Llama-2 (Recognizing Question Entailment)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Xe2U_4tlo6Z2ni-Rfjzwbm_r8ap2nOq
"""

B_SYS, E_SYS = "<<SYS>>\n", "\n<</SYS>>\n\n"
B_INST, E_INST = "[INST]", "[/INST]"

# User-aware RQE
def get_rqe_prompt(_q1, _q2, _BN, _entailment=None):
    system_prompt = "Help recognize question entailment"
    user_prompt = f'''Entailment means:
1. every answer to Q2 must be a partial or complete answer to Q1
2. Q2 must be related to the topics of interest of Q1's asker, denoted by Background Knowledge.
Respond with "positive" for entailment and "negative" for not-entailment. No other words.
Example1:
Q1: How can I read a PDF?
Background Knowledge: python, programming, pandas
Q2: Help me how to open different files such as pdf, docx, etc in Linux?
Answer: negative

Example2:
Q1: How can I read a PDF?
Background Knowledge: linux, debian, filesystems
Q2: Help me how to open different files such as pdf, docx, etc in Linux?
Answer: positive

Now, evaluate the following:
Q1: {_q1}
Background Knowledge: {_BN}
Q2: {_q2}
### Answer:
'''
    prompt = f"{B_INST} {B_SYS}{system_prompt}{E_SYS}{user_prompt}{E_INST}\n\n "
    if _entailment: prompt += f"{_entailment}"
    return prompt



# # User-agnostic RQE
# def get_rqe_prompt(_q1, _q2, _BN, _entailment=None):
#     system_prompt = "Help recognize question entailment"
#     user_prompt = f'''Entailment means:
# every answer to Q2 must be a partial or complete answer to Q1.
# Respond with "positive" for entailment and "negative" for not-entailment. No other words.

# Now, evaluate the following:
# Q1: {_q1}
# Q2: {_q2}
# ### Answer:
# '''
#     prompt = f"{B_INST} {B_SYS}{system_prompt}{E_SYS}{user_prompt}{E_INST}\n\n "
#     if _entailment: prompt += f"{_entailment}"
#     return prompt



def get_response_index(_input_ids, _task):
  _index = None
  _skip_tokens = None
  if _task == 'RQE':
    _index = 0
    _skip_tokens = 10
  if _task == 'SUM':
    _index = 1
    _skip_tokens = 11
  if _task == 'TG':
    _index = 1
    _skip_tokens = 10
  hashtags_indexes = [i for i, n in enumerate(_input_ids) if n == 29937]
  if len(hashtags_indexes) > _index:
    return [i for i, n in enumerate(_input_ids) if n == 29937][_index] + _skip_tokens
  elif _task == 'RQE':
    return 0
  else:
    return -1



# User-aware RQE
def generate_prompt_rqe(data, tokenizer, is_eval):
  promp = None
  q1 = tokenizer.decode(tokenizer(data['q1'])['input_ids'][:200],
                        skip_special_tokens=True,
                        clean_up_tokenization_spaces=True)
  q2 = tokenizer.decode(tokenizer(data['q2'])['input_ids'][:200],
                        skip_special_tokens=True,
                        clean_up_tokenization_spaces=True)
  ub = tokenizer.decode(tokenizer(data['U_Background_kn'])['input_ids'][:100],
                        skip_special_tokens=True,
                        clean_up_tokenization_spaces=True)
  if is_eval: prompt = get_rqe_prompt(q1, q2, ub)
  else: prompt = get_rqe_prompt(q1, q2, ub, data['entailment'])
  return prompt


# # User-agnostic RQE
# def generate_prompt_rqe(data, tokenizer, is_eval):
#   promp = None
#   q1 = tokenizer.decode(tokenizer(data['q1'])['input_ids'][:200],
#                         skip_special_tokens=True,
#                         clean_up_tokenization_spaces=True)
#   q2 = tokenizer.decode(tokenizer(data['q2'])['input_ids'][:200],
#                         skip_special_tokens=True,
#                         clean_up_tokenization_spaces=True)
#   if is_eval: prompt = get_rqe_prompt(q1, q2)
#   else: prompt = get_rqe_prompt(q1, q2, data['entailment'])
#   return prompt