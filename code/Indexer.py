# -*- coding: utf-8 -*-
"""Indexer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UBGlp0usbUaQtj0ZTi2oBD1L7FzlLjgP
"""

batch_size = 128

# model = SentenceTransformer('paraphrase-MiniLM-L6-v2').cuda()
# model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2').cuda()
model = SentenceTransformer('all-mpnet-base-v2').cuda()

def generate_embeddings(texts, batch_size=32):
    embeddings = model.encode(texts, convert_to_tensor=True)
    return embeddings

embeddings = generate_embeddings(MyData['QuestionBody'].tolist(), batch_size=batch_size)
torch.save(embeddings, "PATH/TO/YOUR/DATA.pt")